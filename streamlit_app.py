import streamlit as st
import requests
import json

# Mostrar t√≠tulo y descripci√≥n
st.title("üéì Asistente de B√∫squeda de Becas")
st.write(
    "Este asistente te ayudar√° a encontrar becas de estudio basadas en tus intereses y antecedentes. "
    "Utilizamos inteligencia artificial para procesar tu informaci√≥n y realizar b√∫squedas personalizadas."
)

# Obtener claves API de los secretos de Streamlit
together_api_key = st.secrets["TOGETHER_API_KEY"]
serper_api_key = st.secrets["SERPER_API_KEY"]

# Configurar los endpoints de API y headers
together_url = "https://api.together.xyz/v1/chat/completions"
serper_url = "https://google.serper.dev/search"

together_headers = {
    "Authorization": f"Bearer {together_api_key}",
    "Content-Type": "application/json"
}

serper_headers = {
    "X-API-KEY": serper_api_key,
    "Content-Type": "application/json"
}

# Funci√≥n para realizar b√∫squeda en Google usando la API de Serper
def busqueda_google(consulta):
    payload = json.dumps({"q": consulta})
    response = requests.post(serper_url, headers=serper_headers, data=payload)
    return response.json()

# Funci√≥n para obtener respuesta del LLM usando la API de Together
def obtener_respuesta_llm(mensajes):
    payload = {
        "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "messages": mensajes,
        "max_tokens": 1024,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": ["<|eot_id|>", "<|eom_id|>"],
        "stream": True
    }
    return requests.post(together_url, headers=together_headers, json=payload, stream=True)

# Crear variables de estado de sesi√≥n para almacenar los mensajes del chat y la informaci√≥n del usuario
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []
if "info_usuario" not in st.session_state:
    st.session_state.info_usuario = {}
if "etapa_dialogo" not in st.session_state:
    st.session_state.etapa_dialogo = 0

# Funci√≥n para procesar la respuesta del usuario y actualizar el estado
def procesar_respuesta_usuario(respuesta):
    etapa = st.session_state.etapa_dialogo
    if etapa == 0:
        st.session_state.info_usuario["campo"] = respuesta
    elif etapa == 1:
        st.session_state.info_usuario["ubicacion"] = respuesta
    elif etapa == 2:
        st.session_state.info_usuario["nivel"] = respuesta
    elif etapa == 3:
        st.session_state.info_usuario["nacionalidad"] = respuesta
    elif etapa == 4:
        st.session_state.info_usuario["especifica_nacionalidad"] = respuesta.lower() in ["s√≠", "si", "yes", "y", "s"]
    
    st.session_state.etapa_dialogo += 1

# Mostrar mensajes del chat
for mensaje in st.session_state.mensajes:
    with st.chat_message(mensaje["role"]):
        st.markdown(mensaje["content"])

# Di√°logo principal
preguntas = [
    "¬øEn qu√© campo de estudio est√°s interesado?",
    "¬øEn qu√© pa√≠s o regi√≥n te gustar√≠a estudiar?",
    "¬øQu√© nivel acad√©mico est√°s buscando? (Por ejemplo: Licenciatura, Maestr√≠a, Doctorado, Postdoctorado)",
    "¬øCu√°l es tu nacionalidad?",
    "¬øEst√°s interesado solo en becas espec√≠ficas para tu nacionalidad? (Responde S√≠ o No)"
]

if st.session_state.etapa_dialogo < len(preguntas):
    if st.session_state.etapa_dialogo == 0 or len(st.session_state.mensajes) > 0:
        st.chat_message("assistant").markdown(preguntas[st.session_state.etapa_dialogo])
    
    respuesta_usuario = st.chat_input("Tu respuesta aqu√≠")
    
    if respuesta_usuario:
        st.chat_message("user").markdown(respuesta_usuario)
        st.session_state.mensajes.append({"role": "user", "content": respuesta_usuario})
        procesar_respuesta_usuario(respuesta_usuario)
        st.experimental_rerun()

elif st.session_state.etapa_dialogo == len(preguntas):
    info_usuario = st.session_state.info_usuario
    consulta_busqueda = f"becas para {info_usuario['nivel']} en {info_usuario['campo']} en {info_usuario['ubicacion']}"
    if info_usuario.get('especifica_nacionalidad', False):
        consulta_busqueda += f" para estudiantes de {info_usuario['nacionalidad']}"

    try:
        resultados_busqueda = busqueda_google(consulta_busqueda)
    except Exception as e:
        st.error(f"Error durante la b√∫squeda en Google: {str(e)}")
        resultados_busqueda = {"organic": []}

    contexto = "Resultados de b√∫squeda para becas:\n"
    for i, resultado in enumerate(resultados_busqueda.get('organic', [])[:5], 1):
        contexto += f"{i}. {resultado.get('title', 'Sin t√≠tulo')}: {resultado.get('snippet', 'Sin descripci√≥n')} [Enlace: {resultado.get('link', 'Sin enlace')}]\n"

    prompt = f"""
    Bas√°ndote en las siguientes preferencias del usuario y los resultados de b√∫squeda, recomienda becas adecuadas:
    
    Preferencias del usuario:
    - Campo de estudio: {info_usuario['campo']}
    - Ubicaci√≥n de estudio deseada: {info_usuario['ubicacion']}
    - Nivel acad√©mico: {info_usuario['nivel']}
    - Nacionalidad: {info_usuario['nacionalidad']}
    - Solo interesado en becas espec√≠ficas para su nacionalidad: {"S√≠" if info_usuario.get('especifica_nacionalidad', False) else "No"}

    {contexto}

    Por favor, proporciona una respuesta detallada en espa√±ol con:
    1. Las oportunidades de becas m√°s relevantes.
    2. Enlaces directos a las instituciones que ofrecen estas becas.
    3. Breves explicaciones de por qu√© recomiendas cada instituci√≥n o beca.
    4. Cualquier consejo adicional para el usuario basado en sus preferencias.
    """

    mensajes = [
        {"role": "system", "content": "Eres un asistente de b√∫squeda de becas muy √∫til. Proporciona informaci√≥n detallada y precisa sobre becas basada en las preferencias del usuario y los resultados de la b√∫squeda. Responde siempre en espa√±ol."},
        {"role": "user", "content": prompt}
    ]

    with st.chat_message("assistant"):
        marcador_mensaje = st.empty()
        respuesta_completa = ""

        try:
            respuesta = obtener_respuesta_llm(mensajes)

            for linea in respuesta.iter_lines():
                if linea:
                    try:
                        datos = linea.decode('utf-8').split('data: ', 1)
                        if len(datos) > 1:
                            fragmento = json.loads(datos[1])
                            if fragmento['choices'][0]['finish_reason'] is None:
                                contenido = fragmento['choices'][0]['delta'].get('content', '')
                                respuesta_completa += contenido
                                marcador_mensaje.markdown(respuesta_completa + "‚ñå")
                    except json.JSONDecodeError:
                        continue

            if not respuesta_completa:
                respuesta_completa = "Lo siento, no pude generar una respuesta. Por favor, intenta de nuevo."

        except Exception as e:
            respuesta_completa = f"Ocurri√≥ un error al procesar tu solicitud: {str(e)}"

        marcador_mensaje.markdown(respuesta_completa)

    st.session_state.mensajes.append({"role": "assistant", "content": respuesta_completa})
    st.session_state.etapa_dialogo += 1

# Bot√≥n para iniciar una nueva b√∫squeda de becas
if st.button("Iniciar nueva b√∫squeda de becas"):
    st.session_state.mensajes = []
    st.session_state.info_usuario = {}
    st.session_state.etapa_dialogo = 0
    st.experimental_rerun()
