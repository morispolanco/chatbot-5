<pre><code class="language-python">
import streamlit as st
import requests
import json
from datetime import datetime

# Obtener la fecha actual
fecha_actual = datetime.now().strftime("%d de %B de %Y")

# Mostrar t√≠tulo, descripci√≥n y fecha de b√∫squeda
st.title("üöó Asistente de B√∫squeda de Autom√≥viles Usados en EE.UU.")
st.write(
    f"Fecha de b√∫squeda: {fecha_actual}\n\n"
    "Este asistente te ayudar√° a encontrar autom√≥viles usados en venta en Estados Unidos basados en tus preferencias. "
    "Utilizamos inteligencia artificial para procesar tu informaci√≥n y realizar b√∫squedas personalizadas. "
    "Se mostrar√°n resultados de veh√≠culos disponibles a la fecha de hoy."
)

# Obtener claves API de los secretos de Streamlit
together_api_key = st.secrets["TOGETHER_API_KEY"]
serper_api_key = st.secrets["SERPER_API_KEY"]

# Configurar los endpoints de API y headers
together_url = "https://api.together.xyz/v1/chat/completions"
serper_url = "https://google.serper.dev/search"

together_headers = {
    "Authorization": f"Bearer {together_api_key}",
    "Content-Type": "application/json"
}

serper_headers = {
    "X-API-KEY": serper_api_key,
    "Content-Type": "application/json"
}

# Funci√≥n para realizar b√∫squeda en Google usando la API de Serper
def busqueda_google(consulta):
    payload = json.dumps({"q": consulta})
    response = requests.post(serper_url, headers=serper_headers, data=payload)
    return response.json()

# Funci√≥n para obtener respuesta del LLM usando la API de Together
def obtener_respuesta_llm(mensajes):
    payload = {
        "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
        "messages": mensajes,
        "max_tokens": 1024,
        "temperature": 0.7,
        "top_p": 0.7,
        "top_k": 50,
        "repetition_penalty": 1,
        "stop": ["<|eot_id|>", "<|eom_id|>"],
        "stream": True
    }
    return requests.post(together_url, headers=together_headers, json=payload, stream=True)

# Inicializar variables de estado de sesi√≥n
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []
if "info_usuario" not in st.session_state:
    st.session_state.info_usuario = {}
if "etapa_dialogo" not in st.session_state:
    st.session_state.etapa_dialogo = 0

# Lista de preguntas
preguntas = [
    "¬øQu√© marca y modelo de autom√≥vil est√°s buscando?",
    "¬øEn qu√© rango de a√±os est√°s interesado? (Por ejemplo: 2015-2020)",
    "¬øCu√°l es tu presupuesto m√°ximo en d√≥lares?",
    "¬øEn qu√© estado de EE.UU. est√°s buscando el veh√≠culo?",
    "¬øTienes alguna preferencia en cuanto a caracter√≠sticas espec√≠ficas? (Por ejemplo: bajo kilometraje, tipo de transmisi√≥n, color, etc.)",
    "¬øEst√°s interesado en veh√≠culos que hayan sufrido choques o percances y que por eso est√©n en venta a precios muy bajos? (S√≠/No)"
]

# Mostrar mensajes del chat
for mensaje in st.session_state.mensajes:
    with st.chat_message(mensaje["role"]):
        st.markdown(mensaje["content"])

# Di√°logo principal
if st.session_state.etapa_dialogo < len(preguntas):
    # Mostrar la pregunta actual
    with st.chat_message("assistant"):
        st.markdown(preguntas[st.session_state.etapa_dialogo])
    
    # Esperar la respuesta del usuario
    respuesta_usuario = st.chat_input("Tu respuesta aqu√≠")
    
    if respuesta_usuario:
        # Mostrar la respuesta del usuario
        with st.chat_message("user"):
            st.markdown(respuesta_usuario)
        
        # Guardar la respuesta
        st.session_state.mensajes.append({"role": "user", "content": respuesta_usuario})
        if st.session_state.etapa_dialogo == 0:
            st.session_state.info_usuario["marca_modelo"] = respuesta_usuario
        elif st.session_state.etapa_dialogo == 1:
            st.session_state.info_usuario["rango_a√±os"] = respuesta_usuario
        elif st.session_state.etapa_dialogo == 2:
            st.session_state.info_usuario["presupuesto"] = respuesta_usuario
        elif st.session_state.etapa_dialogo == 3:
            st.session_state.info_usuario["estado"] = respuesta_usuario
        elif st.session_state.etapa_dialogo == 4:
            st.session_state.info_usuario["caracteristicas"] = respuesta_usuario
        elif st.session_state.etapa_dialogo == 5:
            st.session_state.info_usuario["interes_chocados"] = respuesta_usuario.lower() in ["s√≠", "si", "yes", "y"]
        
        # Avanzar a la siguiente etapa
        st.session_state.etapa_dialogo += 1
        st.rerun()

elif st.session_state.etapa_dialogo == len(preguntas):
    # Procesar la informaci√≥n y buscar autom√≥viles
    info_usuario = st.session_state.info_usuario
    consulta_busqueda = f"used {info_usuario['marca_modelo']} for sale {info_usuario['rango_a√±os']} under {info_usuario['presupuesto']} in {info_usuario['estado']} {info_usuario['caracteristicas']}"
    
    if info_usuario['interes_chocados']:
        consulta_busqueda += " salvage title"

    try:
        resultados_busqueda = busqueda_google(consulta_busqueda)
    except Exception as e:
        st.error(f"Error durante la b√∫squeda en Google: {str(e)}")
        resultados_busqueda = {"organic": []}

    contexto = "Resultados de b√∫squeda para autom√≥viles usados:\n"
    for i, resultado in enumerate(resultados_busqueda.get('organic', [])[:5], 1):
        contexto += f"{i}. {resultado.get('title', 'Sin t√≠tulo')}: {resultado.get('snippet', 'Sin descripci√≥n')} [Enlace: {resultado.get('link', 'Sin enlace')}]\n"

    prompt = f"""
    Bas√°ndote en las siguientes preferencias del usuario y los resultados de b√∫squeda, recomienda autom√≥viles usados adecuados que est√©n disponibles actualmente (fecha actual: {fecha_actual}):
    
    Preferencias del usuario:
    - Marca y modelo: {info_usuario['marca_modelo']}
    - Rango de a√±os: {info_usuario['rango_a√±os']}
    - Presupuesto m√°ximo: {info_usuario['presupuesto']}
    - Estado de EE.UU.: {info_usuario['estado']}
    - Caracter√≠sticas espec√≠ficas: {info_usuario['caracteristicas']}
    - Inter√©s en veh√≠culos chocados o con percances: {"S√≠" if info_usuario['interes_chocados'] else "No"}

    {contexto}

    Por favor, proporciona una respuesta detallada en espa√±ol con:
    1. Los autom√≥viles usados m√°s relevantes que coincidan con las preferencias del usuario.
    2. Enlaces directos a los anuncios de estos veh√≠culos. Aseg√∫rate de que los enlaces proporcionados sean los que dirigen directamente al anuncio espec√≠fico del veh√≠culo.
    3. Precio de cada veh√≠culo.
    4. Breves descripciones de las caracter√≠sticas principales de cada veh√≠culo.
    5. Si el usuario est√° interesado en veh√≠culos chocados, menciona cualquier informaci√≥n relevante sobre el estado del veh√≠culo y los posibles riesgos o beneficios.
    6. Cualquier consejo adicional para el usuario basado en sus preferencias.

    Aseg√∫rate de incluir solo veh√≠culos que est√©n disponibles en la fecha actual ({fecha_actual}).
    Al final de tu respuesta, indica nuevamente la fecha de b√∫squeda.
    """

    mensajes = [
        {"role": "system", "content": "Eres un asistente de b√∫squeda de autom√≥viles usados muy √∫til. Proporciona informaci√≥n detallada y precisa sobre veh√≠culos basada en las preferencias del usuario y los resultados de la b√∫squeda. Responde siempre en espa√±ol y aseg√∫rate de incluir solo veh√≠culos disponibles actualmente. Los enlaces deben dirigir directamente a los anuncios espec√≠ficos de los veh√≠culos."},
        {"role": "user", "content": prompt}
    ]

    with st.chat_message("assistant"):
        marcador_mensaje = st.empty()
        respuesta_completa = ""

        try:
            respuesta = obtener_respuesta_llm(mensajes)

            for linea in respuesta.iter_lines():
                if linea:
                    try:
                        datos = linea.decode('utf-8').split('data: ', 1)
                        if len(datos) > 1:
                            fragmento = json.loads(datos[1])
                            if fragmento['choices'][0]['finish_reason'] is None:
                                contenido = fragmento['choices'][0]['delta'].get('content', '')
                                respuesta_completa += contenido
                                marcador_mensaje.markdown(respuesta_completa + "‚ñå")
                    except json.JSONDecodeError:
                        continue

            if not respuesta_completa:
                respuesta_completa = "Lo siento, no pude encontrar autom√≥viles usados que coincidan con tus criterios. Por favor, intenta ampliar tu b√∫squeda o consultar m√°s tarde."

            respuesta_completa += f"\n\nFecha de b√∫squeda: {fecha_actual}"

        except Exception as e:
            respuesta_completa = f"Ocurri√≥ un error al procesar tu solicitud: {str(e)}"

        marcador_mensaje.markdown(respuesta_completa)

    st.session_state.mensajes.append({"role": "assistant", "content": respuesta_completa})
    st.session_state.etapa_dialogo += 1

# Bot√≥n para iniciar una nueva b√∫squeda de autom√≥viles
if st.button("Iniciar nueva b√∫squeda de autom√≥viles"):
    st.session_state.mensajes = []
    st.session_state.info_usuario = {}
    st.session_state.etapa_dialogo = 0
    st.rerun()

# Mostrar la fecha de b√∫squeda al final de la p√°gina
st.write(f"\nFecha de b√∫squeda: {fecha_actual}")
</code></pre>
